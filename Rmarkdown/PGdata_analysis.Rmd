---
title: "Empirical Example TV-DPCM"
author: "Sebastian Castro-Alvarez"
date: "`r format(Sys.Date(), '%B %d del %Y')`"
header-includes:
  - \usepackage{booktabs}
  - \usepackage{longtable}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage{float}
  - \usepackage{amsmath}
output: 
  bookdown::pdf_document2:
    toc: false
    keep_tex: true
    number_section: false
bibliography: references.bib
csl: apa7.csl
link-citations: true
always_allow_html: true
---

```{r setup, include=FALSE}
library(knitr)
library(bookdown)
library(kableExtra)
knitr::opts_chunk$set(echo = FALSE, fig.height = 4, fig.width = 6, fig.pos = "!H",  
                      warning=FALSE, message=FALSE)

#rmarkdown::render("Rmarkdown/PGdata_analysis.Rmd")
```

```{r pre-env}
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
library(bayesplot)
color_scheme_set("darkgray")

source("../R/IRT_models.R")
source("../R/IRT_plots.R")
source("../R/tvdpcm2stan.R")

set.seed(2022)

model <- stan_model(file = "../Stan/tv_dpcm_int_v5.1.stan", verbose = FALSE)
```

# Using the TV-DPCM to Analyze Mental Unrest 

To exemplify how to use an interpret the TV-DPCM, in this section, we analyzed mood data from one subject that were collected between August 2012 and April 2013. These data were retrieved from \\citet{Kossakowski2017} and was previously analyzed by \\citet{Wichers2016}. The data come from a 57 years old male (at the time) that had been diagnosed with major depressive disorder. The participant completed up to 10 semi-random assessments per day for 239 days. During this period, the participant also followed a blind gradual reduction of their anti-depressant medication dosage. In what follows, the items of interest and the data collection procedure are described in detail. Then, descriptive statistics concerning the distribution of the items scores are presented. Finally, the TV-DPCM is adjusted to the data in order to study the psychological dynamics of mental unrest and the performances of the items of the ESM questionnaire.

```{r data}
PG_data <- read.csv("../ESMdata/ESMdata.csv")
PG_data <- PG_data[!is.na(PG_data$pat_restl), ]

# Select variables
PG_data <- PG_data[, c("date", "phase", "concentrat", "beepno", "resptime_s", 
                       grep("mood", names(PG_data), value = TRUE)[-13], 
                       grep("pat", names(PG_data), value = TRUE))]

# Transform Dates
PG_data$date       <- as.Date(PG_data$date, format = "%d/%m/%y")
PG_data$resptime_s <- as.POSIXct(paste(PG_data$date, PG_data$resptime_s))
```

```{r components}
pa <- c("mood_relaxed", "mood_satisfi", "mood_enthus", 
        "mood_cheerf", "mood_strong")
na <- c("mood_down", "mood_lonely", "mood_anxious", 
        "mood_guilty")
mu <- c("mood_irritat", "pat_restl", "pat_agitate")
```

## Data Collection and Procedure.

As mentioned before, the participant filled in an ESM questionnaire up to 10 times a day for 239 days. The questionnaire was programmed at random moments within 90-minute intervals that were set between 07:30 AM and 10:30 PM. After the beep signal, the participant had a 10-minute window to complete the questionnaire, which consisted of 50 momentary assessment items that measured different emotions (e.g., feeling enthusiastic or feeling lonely), self-esteem, and descriptions of the situation such as whether the participant was alone or doing something. Furthermore, additional items were used at certain beep signals to measure, for example, sleep quality and depressive symptoms. These items were filled up on a daily or weekly basis. All the momentary assessment items were measured on a 7-point Likert scale from "not feeling the state" to "feeling the state very much". \\citet{Wichers2016} ran a principal component analysis on the momentary assessment items and extracted three components that represented positive affect, negative affect, and mental unrest. For this reason, in the following analysis, we selected the momentary items that measure mental unrest. These items are: "I feel irritated", "I feel restless", and "I feel agitated". The participant completed a total of 1473 assessments. This means that on average 6.2 assessments were completed per day.

## Descriptives
```{r index}
index <- trunc(seq(1, nrow(PG_data), length.out = 100))
```

Figure \@ref(fig:timeseries) presents the observed mean scores of the items of mental unrest for every `r median(diff(index))`beeps. This shows that the participant's mental unrest had an increasing trend over time. This increase was connected to the end of the use of antidepressants by the participant \\citep{Wichers2016}. 

```{r timeseries, fig.cap = "Observed Mean Scores of the Mental Unrest Items"}
plot(index, 
     rowMeans(PG_data[, mu])[index], 
     type = "l", ylab = "Mean Scores", xlab = "Beep Number")
rm(index)
```

Next, in Figure \@ref(fig:itemdist), we present the distribution of the responses to the items of mental unrest. The responses to these items show a biased distribution towards the lowest responses categories. In fact, the seventh response category was only used on two beeps for the item *irritated* and it was never used in the other two items. Moreover, the sixth category was only chosen on 12, 1, and 4 beeps for each of the items of mental unrest. For the analyses, the responses to categories 5 through 7 are merged into one, as having unused response categories is problematic for IRT analyses. 

```{r itemdist, fig.cap = "Item Score Distribution of the Items of Negative Affect"}
par(mfrow = c(3,1), mar = c(5, 3, 0.5, 1) + 0.1)
barplot(table(factor(PG_data[, mu[1]], levels = 1:7)), 
        ylim = c(0, 601), las = 1, xlab = "Irritated")
barplot(table(factor(PG_data[, mu[2]], levels = 1:7)), 
        ylim = c(0, 601), las = 1, xlab = "Restless")
barplot(table(factor(PG_data[, mu[3]], levels = 1:7)), 
        ylim = c(0, 601), las = 1, xlab = "Agitated")
```

## Fitting the TV-DPCM

```{r addNA}
# Add ID dummy and time as numeric
PG_data$id   <- 1
# Create and ordered variable of the day number
PG_data$dayno <- as.numeric(PG_data$date) - as.numeric(PG_data$date[1])
# Combine the day number and the beep number
PG_data$time  <- PG_data$beepno + 16 * PG_data$dayno
# Include NA
PG_data_na <- esmpack:::expand.esm(data = PG_data, 
                                   id   = "id", 
                                   time = "time",
                                   tinterval = 1, 
                                   include   = c(mu, na, pa))
```

One of the assumptions of the TV-DPCM is that the time interval between consecutive observations is the same for the whole duration of the data collection. This was clearly not the case with the data at hand. One way to address this issue is to include missing values in order to make the time interval between observations approximately the same \\citep{Asparouhov2018}. This approach have been shown to be useful to deal with unequal time intervals and the results from these kind of analyses are comparable with results from continuous time models. Given this, we also implemented this approach in the TV-DPCM analysis of the mental unrest items. For this, we divided the days in 90-minute time windows, for a total of 16 time windows per day. Observations within any of these time windows were considered as a representation of the mental unrest state of the participant for that time point. When no observations were available, "missing values" were included in the date set. By doing this, we added `r nrow(PG_data_na) - nrow(PG_data)` row of missing values for a total number of time windows of `r nrow(PG_data_na)`. Furthermore, as mentioned before, we collapsed the response categories from 5 to 7 into one. As a result, there are 5 response categories for each item, which means that 4 threshold parameters are estimated per item. 

```{r data2stan}
responses <- PG_data_na[, mu]
responses[responses >= 5] <- 5

I  <- ncol(responses)
nT <- nrow(responses)
K  <- max(responses, na.rm = TRUE)

standata <- tvdpcm2stan_data(resp = as.matrix(responses),
                             I    = I,
                             K    = K,
                             nT   = nT,
                             n_knots  = 8,
                             s_degree = 3)
```

```{r stanfit}
rdsfile <- "../Fits/MUwithNA"

tvdpcm_inits <- function() {
              list(lambda = runif(1, -1, 1),
                   beta   = array(rnorm(I * (K - 1), 0, 3), dim = c(I, K - 1)),
                   inno   = rnorm(nT, 0, 3),
                   sigma  = rlnorm(1, 1))
            }

if (!file.exists(paste0(rdsfile, ".rds"))) {
  begin.time <- proc.time()
  fit <- sampling(model,                  # Stan model. 
                  data = standata,        # Data.
                  iter = 2000,            # Number of iterations.
                  chains  = 3,            # Number of chains.
                  warmup  = 500,          # Burn-in samples.
                  init    = tvdpcm_inits, # Initial values
                  seed = 2022,            # Seed
                  pars = c("beta", "theta", "lambda",
                           "sigma2", "pvar", "attractor"),
                  control = list(adapt_delta   = 0.99,
                                 max_treedepth = 15) # Other parameters to control sampling behavior.
                  ) 
  run.time <- proc.time() - begin.time
  rm(begin.time)
  
  saveRDS(fit, file = paste0(rdsfile, ".rds"))
  saveRDS(run.time, file = paste0(rdsfile, "_time.rds"))
} else {
  fit      <- readRDS(paste0(rdsfile, ".rds"))
  run.time <- readRDS(paste0(rdsfile, "_time.rds"))
}
```

```{r diag}
stan.diag <- monitor(extract(fit, permuted = FALSE, inc_warmup = FALSE), 
                                 warmup = 0, print = FALSE)
            
ndiv  <- get_num_divergent(fit)     # number of divergent transitions
nbfmi <- get_low_bfmi_chains(fit)   # number of chains with a low bayesian fraction missing information 
ntree <- get_num_max_treedepth(fit) # number of transitions that exceeded the maximum treedepth
nbulk <- sum(stan.diag$Bulk_ESS < 100 * dim(fit)[2]) # number of parameters with low bulk ESS
ntail <- sum(stan.diag$Tail_ESS < 100 * dim(fit)[2]) # number of parameters with low tail ESS
          
            #max Rhat
maxRhat <- round(max(rhat(fit, pars = c("beta", "theta", "lambda", 
                                        "sigma2", "pvar", "attractor"))), 4)
nRhat   <- sum(rhat(fit, pars = c("beta", "theta", "lambda",
                                  "sigma2", "pvar", "attractor")) > 1.05)
```

Next, to fit the TV-DPCM to the data, we used the same setup for the Hamiltonian Monte Carlo algorithm as we did in the simulation study. This means that we ran three chains in parallel, each with 2000 iterations, 500 of which were discarded as burnin, and we kept the same values for the *adapt_delta* (0.99) and *max_treedepth* (15) parameters. This analysis took `r ceiling(run.time[3]/60)` minutes to run. To check convergence of the model, we examined the diagnostics provided in Stan for the HMC algorithm. According to these diagnostics, the model converged successfully. This can be seen in Figures \@ref(fig:rhats) and \@ref(fig:trace). On the one hand, Figure \@ref(fig:rhats) presents the corresponding Gelman-Rubin statistics for the parameters in the model, all of which are lower than 1.05. On the other hand, Figure \@ref(fig:trace) presents the trace plots for a few selected parameters. These trace plots form fat caterpillars, which indicate that the different chains sampled from the same posterior distributions.     

```{r rhats, fig.cap = "Gelman-Rubin Statistics for the Estimated Parameters of the TV-DPCM"}
mcmc_rhat(rhat(fit))
```

```{r trace, fig.cap = "Traceplots of Selected Parameters"}
parameters <- c(paste0("beta[", sample(1:I, 1), ",", sample(1:(K - 1), 1), "]"),
                paste0("theta[", sample(which(!is.na(responses[, 1])), 1), "]"),
                "lambda", "sigma2")
fit.array <- as.array(fit, pars = parameters)

parameters[1] = gsub("beta", "delta", parameters[1])
parameters[1] = gsub(",", "", parameters[1])
parameters[2] = parameters[2]
parameters[3] = 'varphi'
parameters[4] = 'Psi'

dimnames(fit.array) [[3]] <- parameters

mcmc_trace(fit.array, facet_args = list(labeller = "label_parsed"))
```

```{r acf-plots, fig.cap = "Autocorrelation Plots of Selected Parameters"}
mcmc_acf(fit.array, 
         facet_args = list(labeller = "label_parsed"),
         lags = 20)
```


```{r estimates}
estimates <- as.data.frame(summary(fit, pars = c("beta", "lambda", "sigma2"))$summary)

estimates <- estimates[, c(1, 3, 4, 8, 9)]

estimates[, 3] <- paste0("(", round(estimates[, 3], 2), ",", round(estimates[, 4], 2), ")")

estimates        <- estimates[, -4]

names(estimates) <- c("Mean", "SD", "C.I.", "ESS")

row.names(estimates) <- c(paste0("$\\delta_{", 
                                 rep(1:I, each = K - 1), 
                                 rep(1:(K - 1), times = I),
                                 "}$"),
                          "$\\varphi$", "$\\Psi$")

# Extract all estimates
sum.fit <- list()

sum.fit$beta   <- summary(fit, pars = "beta")$summary
sum.fit$theta  <- summary(fit, pars = "theta")$summary
sum.fit$lambda <- summary(fit, pars = "lambda")$summary
sum.fit$sigma2 <- summary(fit, pars = "sigma2")$summary
sum.fit$pvar  <- summary(fit, pars = "pvar")$summary
sum.fit$attractor <- summary(fit, pars = "attractor")$summary

# Create index to plot latent dynamics
index <- trunc(seq(1, standata$nT, length.out = 200))
```

Table \@ref(tab:est-table) shows the estimated values (i.e., the mean), the standard deviation, the credibility interval, and the effective sample size of the threshold parameters, the autoregressive effect, and the variance of the innovations. Note that the threshold parameters are ordered within items. This is a good sign, as it means that the 5 response categories are clearly differentiated by the participant. Next, the estimated autoregressive effect was `r round(sum.fit$lambda[, 1], 2)`. This is partially in line with some of the results by \\citet{Wichers2016}, who found that the autoregressive effect of metal unrest was 0.45 during the double blind phase with antidepressant reduction. Lastly, the variance of the innovations was `r round(sum.fit$sigma2[, 1], 2)`.

```{r est-table}
kbl(estimates, align = "c", booktabs = TRUE, caption = "Estimated Parameters of the TV-DPCM", escape = FALSE, digits = c(2, 2, NA, 0))
```

The estimates of the latent state dispositions and the time-varying attractor are presented in Figure \@ref(fig:est-trend). The estimated latent states for every `r median(diff(index))` beeps are displayed. These estimated states varied between `r round(min(sum.fit$theta[, 1]), 2)` and `r round(max(sum.fit$theta[, 1]), 2)`, and their mean was `r round(mean(sum.fit$theta[, 1]), 2)`. Next, the attractor is presented alongside with its credibility interval band, which shows that the trend increased over time.     

```{r est-trend, fig.cap = "Estimated Latent State Dispositions and Trend"}
plot(standata$time[index], sum.fit$theta[, 1][index],
     type = "l", ylim = c(-8, 8), col = gray(0.5), lwd = 1,
     ylab = "Latent State Disposition", xlab = "Beep Number")
polygon(c(standata$time, rev(standata$time)),
        c(sum.fit$attractor[, 4], rev(sum.fit$attractor[, 8])),
        border = NA,
        col = gray(0.75, 0.25))
# polygon(c(standata$time, rev(standata$time)),
#         c(sum.fit$theta[, 4], rev(sum.fit$theta[, 8])),
#         border = NA,
#         col = rgb(1, 0, 0, 0.25))
lines(standata$time, sum.fit$attractor[, 1],
      col = 1, lwd = 2)
```

Finally, one of the main advantages of IRT models is that these models allows studying the properties of the items and the test. In this context, IRT provides the item characteristic functions (ICF), the item information functions (IIF), and the test information function (TIF). These functions for the TV-DPCM fitted to the items of mental unrest are presented in Figures \@ref(fig:ICC) to \@ref(fig:TIF). In general, the ICFs of each item show that the curves for each response category are nicely ordered and that each of them get to have the highest response probability at some point in the latent continuum. The item *restless* seems to be the best at differentiating between states of metal unrest given that the curves of each response category are clearly defined and can be easily differentiated from each other. However, when looking at the IIF, we see that the item *irritated* is the most informative item between -2 and 2, this means that this item is very useful at measuring medium levels of mental unrest. In contrast, the items *restless* and *agitated* seem to be more informative and more useful to measure high levels of mental unrest. Lastly, the TIF shows that, overall, these three items seem to form a useful scale to measure medium and high levels of the participant's mental unrest but it falls short at might have high indices of measurement error at the lower levels.   

```{r ICC, fig.height = 6, fig.cap = "Item Characteristic Functions for the Mental Unrest Items"}
par(mfrow = c(3, 1))

plot.ICC(object = fit, data = standata, range = c(-6, 6), quiet = TRUE,
         item_labels = c("Irritated", "Restless", "Agitated"), 
         col = gray((0:(K - 1))/K))
```

```{r IIF, fig.cap = "Item Information Functions of the Items of Mental Unrest"}
plot.IIF(object = fit, data = standata, type = "IIF", 
         item_labels = c("Irritated", "Restless", "Agitated"), 
         col = gray((0:(I-1))/I), range = c(-6, 6))

```


```{r TIF, fig.cap = "Test Information Function of the Items of Mental Unrest"}
plot.IIF(object = fit, data = standata, range = c(-6, 6), type = "TIF")
```

```{r clean1}
rm(estimates, fit, responses, stan.diag, standata,
   sum.fit, fit.array, I, index, K, maxRhat,
   nbfmi, nbulk, ndiv, nRhat, nT, ntail, ntree,
   parameters, rdsfile, run.time)
```

\newpage

# Fitting the PCM for Comparison

```{r pcmdata}
modelpcm  <- stan_model(file = "../Stan/irt_pcm_long.stan", verbose = FALSE)

responses <- PG_data[, mu]
responses[responses >= 5] <- 5

I  <- ncol(responses)
nT <- nrow(responses)
K  <- max(responses, na.rm = TRUE)

standatapcm <- tvdpcm2stan_data(resp = as.matrix(responses),
                                I    = I,
                                K    = K,
                                nT   = nT,
                                n_knots  = 8,
                                s_degree = 3)
```


```{r pcmfit}
inits <- function() {
list(beta   = array(rnorm(I * (K - 1), 0, 3), dim = c(I, K - 1)),
     theta   = rnorm(nT, 0, 3))
}

rdsfile <- "../Fits/MU_PCM"

if (!file.exists(paste0(rdsfile, ".rds"))) {
  begin.time <- proc.time()
  fit <- sampling(modelpcm,                  # Stan model. 
                  data = standatapcm,        # Data.
                  iter = 2000,            # Number of iterations.
                  chains  = 3,            # Number of chains.
                  warmup  = 500,          # Burn-in samples.
                  init    = inits, # Initial values
                  seed = 2022,            # Seed
                  pars = c("beta", "theta"),
                  control = list(adapt_delta   = 0.99,
                                 max_treedepth = 15) # Other parameters to control sampling behavior.
                  ) 
  run.time <- proc.time() - begin.time
  rm(begin.time)
  
  saveRDS(fit, file = paste0(rdsfile, ".rds"))
  saveRDS(run.time, file = paste0(rdsfile, "_time.rds"))
} else {
  fit      <- readRDS(paste0(rdsfile, ".rds"))
  run.time <- readRDS(paste0(rdsfile, "_time.rds"))
}
```

```{r diag-pcm}
stan.diag <- monitor(extract(fit, permuted = FALSE, inc_warmup = FALSE), 
                                 warmup = 0, print = FALSE)
            
ndiv  <- get_num_divergent(fit)     # number of divergent transitions
nbfmi <- get_low_bfmi_chains(fit)   # number of chains with a low bayesian fraction missing information 
ntree <- get_num_max_treedepth(fit) # number of transitions that exceeded the maximum treedepth
nbulk <- sum(stan.diag$Bulk_ESS < 100 * dim(fit)[2]) # number of parameters with low bulk ESS
ntail <- sum(stan.diag$Tail_ESS < 100 * dim(fit)[2]) # number of parameters with low tail ESS
          
            #max Rhat
maxRhat <- round(max(rhat(fit, pars = c("beta", "theta"))), 4)
nRhat   <- sum(rhat(fit, pars = c("beta", "theta")) > 1.05)
```


```{r rhats-pcm, fig.cap = "Gelman-Rubin Statistics for the Estimated Parameters of the PCM"}
mcmc_rhat(rhat(fit))
```

```{r trace-pcm, fig.cap = "Traceplots of Selected Parameters"}
parameters <- c(paste0("beta[", sample(1:I, 1), ",", sample(1:(K - 1), 1), "]"),
                paste0("theta[", sample(which(!is.na(responses[, 1])), 1), "]"))
fit.array <- as.array(fit, pars = parameters)

parameters[1] = gsub("beta", "delta", parameters[1])
parameters[1] = gsub(",", "", parameters[1])
parameters[2] = parameters[2]

dimnames(fit.array) [[3]] <- parameters

mcmc_trace(fit.array, facet_args = list(labeller = "label_parsed"))
```

```{r acf-plots, fig.cap = "Autocorrelation Plots of Selected Parameters"}

mcmc_acf(fit.array, 
         facet_args = list(labeller = "label_parsed"),
         lags = 20)
```


```{r estimates-pcm}
estimates <- as.data.frame(summary(fit, pars = "beta")$summary)

estimates <- estimates[, c(1, 3, 4, 8, 9)]

estimates[, 3] <- paste0("(", round(estimates[, 3], 2), ",", round(estimates[, 4], 2), ")")

estimates        <- estimates[, -4]

names(estimates) <- c("Mean", "SD", "C.I.", "ESS")

row.names(estimates) <- c(paste0("$\\delta_{", 
                                 rep(1:I, each = K - 1), 
                                 rep(1:(K - 1), times = I),
                                 "}$"))

# Extract all estimates
sum.fit <- list()

sum.fit$beta   <- summary(fit, pars = "beta")$summary
sum.fit$theta  <- summary(fit, pars = "theta")$summary

# Create index to plot latent dynamics
index <- trunc(seq(1, standatapcm$nT, length.out = 200))
```


```{r est-table-pcm}
kbl(estimates, align = "c", booktabs = TRUE, caption = "Estimated Parameters of the PCM", escape = FALSE, digits = c(2, 2, NA, 0))
```


```{r est-trend-pcm, fig.cap = "Estimated Latent State Dispositions and Trend"}
plot(standatapcm$time[index], sum.fit$theta[, 1][index],
     type = "l", ylim = c(-1.5, 3), col = gray(0.5), lwd = 1,
     ylab = "Latent State Disposition", xlab = "Beep Number")
# polygon(c(standata$time, rev(standata$time)),
#         c(sum.fit$theta[, 4], rev(sum.fit$theta[, 8])),
#         border = NA,
#         col = rgb(1, 0, 0, 0.25))
```


```{r ICC-pcm, fig.height = 6, fig.cap = "Item Characteristic Functions for the Mental Unrest Items given the PCM"}
par(mfrow = c(3, 1))

plot.ICC(object = fit, data = standatapcm, range = c(-6, 6), quiet = TRUE,
         item_labels = c("Irritated", "Restless", "Agitated"), 
         col = gray((0:(K - 1))/K))
```

```{r IIF-pcm, fig.cap = "Item Information Functions of the Items of Mental Unrest given the PCM"}
plot.IIF(object = fit, data = standatapcm, type = "IIF", 
         item_labels = c("Irritated", "Restless", "Agitated"), 
         col = gray((0:(I-1))/I), range = c(-6, 6))

```


```{r TIF-pcm, fig.cap = "Test Information Function of the Items of Mental Unrest"}
plot.IIF(object = fit, data = standatapcm, range = c(-6, 6), type = "TIF")
```

```{r clean2}
rm(estimates, fit, responses, stan.diag, standatapcm,
   sum.fit, fit.array, I, index, K, maxRhat,
   nbfmi, nbulk, ndiv, nRhat, nT, ntail, ntree,
   parameters, rdsfile, run.time)
```

\newpage

## Fitting the TV-DPCM to NA items

```{r data2stan-na}
responses <- PG_data_na[, na]
responses[responses < -2] <- -2
responses[responses > 2]  <- 2
responses <- responses + 3

I  <- ncol(responses)
nT <- nrow(responses)
K  <- max(responses, na.rm = TRUE)

standata <- tvdpcm2stan_data(resp = as.matrix(responses),
                             I    = I,
                             K    = K,
                             nT   = nT,
                             n_knots  = 8,
                             s_degree = 3)
```

```{r stanfit-na}
rdsfile <- "../Fits/NegAwithNA"

tvdpcm_inits <- function() {
              list(lambda = runif(1, -1, 1),
                   beta   = array(rnorm(I * (K - 1), 0, 3), dim = c(I, K - 1)),
                   inno   = rnorm(nT, 0, 3),
                   sigma  = rlnorm(1, 1))
            }

if (!file.exists(paste0(rdsfile, ".rds"))) {
  begin.time <- proc.time()
  fit <- sampling(model,                  # Stan model. 
                  data = standata,        # Data.
                  iter = 2000,            # Number of iterations.
                  chains  = 3,            # Number of chains.
                  warmup  = 500,          # Burn-in samples.
                  init    = tvdpcm_inits, # Initial values
                  seed = 2022,            # Seed
                  pars = c("beta", "theta", "lambda",
                           "sigma2", "pvar", "attractor"),
                  control = list(adapt_delta   = 0.99,
                                 max_treedepth = 15) # Other parameters to control sampling behavior.
                  ) 
  run.time <- proc.time() - begin.time
  rm(begin.time)
  
  saveRDS(fit, file = paste0(rdsfile, ".rds"))
  saveRDS(run.time, file = paste0(rdsfile, "_time.rds"))
} else {
  fit      <- readRDS(paste0(rdsfile, ".rds"))
  run.time <- readRDS(paste0(rdsfile, "_time.rds"))
}
```

```{r diag-na}
stan.diag <- monitor(extract(fit, permuted = FALSE, inc_warmup = FALSE), 
                                 warmup = 0, print = FALSE)
            
ndiv  <- get_num_divergent(fit)     # number of divergent transitions
nbfmi <- get_low_bfmi_chains(fit)   # number of chains with a low bayesian fraction missing information 
ntree <- get_num_max_treedepth(fit) # number of transitions that exceeded the maximum treedepth
nbulk <- sum(stan.diag$Bulk_ESS < 100 * dim(fit)[2]) # number of parameters with low bulk ESS
ntail <- sum(stan.diag$Tail_ESS < 100 * dim(fit)[2]) # number of parameters with low tail ESS
          
            #max Rhat
maxRhat <- round(max(rhat(fit, pars = c("beta", "theta", "lambda", 
                                        "sigma2", "pvar", "attractor"))), 4)
nRhat   <- sum(rhat(fit, pars = c("beta", "theta", "lambda",
                                  "sigma2", "pvar", "attractor")) > 1.05)
```

```{r rhats-na, fig.cap = "Gelman-Rubin Statistics for the Estimated Parameters of the TV-DPCM"}
mcmc_rhat(rhat(fit))
```

```{r trace-na, fig.cap = "Traceplots of Selected Parameters"}
parameters <- c(paste0("beta[", sample(1:I, 1), ",", sample(1:(K - 1), 1), "]"),
                paste0("theta[", sample(which(!is.na(responses[, 1])), 1), "]"),
                "lambda", "sigma2")
fit.array <- as.array(fit, pars = parameters)

parameters[1] = gsub("beta", "delta", parameters[1])
parameters[1] = gsub(",", "", parameters[1])
parameters[2] = parameters[2]
parameters[3] = 'varphi'
parameters[4] = 'Psi'

dimnames(fit.array) [[3]] <- parameters

mcmc_trace(fit.array, facet_args = list(labeller = "label_parsed"))
```

```{r acf-plots-na, fig.cap = "Autocorrelation Plots of Selected Parameters"}
mcmc_acf(fit.array, 
         facet_args = list(labeller = "label_parsed"),
         lags = 20)
```

```{r estimates-na}
estimates <- as.data.frame(summary(fit, pars = c("beta", "lambda", "sigma2"))$summary)

estimates <- estimates[, c(1, 3, 4, 8, 9)]

estimates[, 3] <- paste0("(", round(estimates[, 3], 2), ",", round(estimates[, 4], 2), ")")

estimates        <- estimates[, -4]

names(estimates) <- c("Mean", "SD", "C.I.", "ESS")

row.names(estimates) <- c(paste0("$\\delta_{", 
                                 rep(1:I, each = K - 1), 
                                 rep(1:(K - 1), times = I),
                                 "}$"),
                          "$\\varphi$", "$\\Psi$")

# Extract all estimates
sum.fit <- list()

sum.fit$beta   <- summary(fit, pars = "beta")$summary
sum.fit$theta  <- summary(fit, pars = "theta")$summary
sum.fit$lambda <- summary(fit, pars = "lambda")$summary
sum.fit$sigma2 <- summary(fit, pars = "sigma2")$summary
sum.fit$pvar  <- summary(fit, pars = "pvar")$summary
sum.fit$attractor <- summary(fit, pars = "attractor")$summary

# Create index to plot latent dynamics
index <- trunc(seq(1, standata$nT, length.out = 200))
```

```{r est-table-na}
kbl(estimates, align = "c", booktabs = TRUE, caption = "Estimated Parameters of the TV-DPCM", escape = FALSE, digits = c(2, 2, NA, 0))
```

```{r est-trend-na, fig.cap = "Estimated Latent State Dispositions and Trend"}
plot(standata$time[index], sum.fit$theta[, 1][index],
     type = "l", ylim = c(-8, 8), col = gray(0.5), lwd = 1,
     ylab = "Latent State Disposition", xlab = "Beep Number")
polygon(c(standata$time, rev(standata$time)),
        c(sum.fit$attractor[, 4], rev(sum.fit$attractor[, 8])),
        border = NA,
        col = gray(0.75, 0.25))
# polygon(c(standata$time, rev(standata$time)),
#         c(sum.fit$theta[, 4], rev(sum.fit$theta[, 8])),
#         border = NA,
#         col = rgb(1, 0, 0, 0.25))
lines(standata$time, sum.fit$attractor[, 1],
      col = 1, lwd = 2)
```

```{r ICC-na, fig.height = 6, fig.cap = "Item Characteristic Functions for the Mental Unrest Items"}
par(mfrow = c(4, 1))

plot.ICC(object = fit, data = standata, range = c(-8, 8), quiet = TRUE,
         item_labels = c("Down", "Lonely", "Anxious", "Guilty"), 
         col = gray((0:(K - 1))/K))
```

```{r IIF-na, fig.cap = "Item Information Functions of the Items of Mental Unrest"}
plot.IIF(object = fit, data = standata, type = "IIF", 
         item_labels = c("Irritated", "Restless", "Agitated"), 
         col = gray((0:(I-1))/I), range = c(-6, 6))

```

```{r TIF-na, fig.cap = "Test Information Function of the Items of Mental Unrest"}
plot.IIF(object = fit, data = standata, range = c(-6, 6), type = "TIF")
```

```{r clean3}
rm(estimates, fit, responses, stan.diag, standata,
   sum.fit, fit.array, I, index, K, maxRhat,
   nbfmi, nbulk, ndiv, nRhat, nT, ntail, ntree,
   parameters, rdsfile, run.time)
```

\newpage

## Fitting the TV-DPCM to PA items

```{r data2stan-pa}
responses <- PG_data_na[, pa]
responses[responses < 2] <- 2
responses[responses > 6] <- 6
responses <- responses - 1

I  <- ncol(responses)
nT <- nrow(responses)
K  <- max(responses, na.rm = TRUE)

standata <- tvdpcm2stan_data(resp = as.matrix(responses),
                             I    = I,
                             K    = K,
                             nT   = nT,
                             n_knots  = 8,
                             s_degree = 3)
```

```{r stanfit-pa}
rdsfile <- "../Fits/PosAwithNA"

tvdpcm_inits <- function() {
              list(lambda = runif(1, -1, 1),
                   beta   = array(rnorm(I * (K - 1), 0, 3), dim = c(I, K - 1)),
                   inno   = rnorm(nT, 0, 3),
                   sigma  = rlnorm(1, 1))
            }

if (!file.exists(paste0(rdsfile, ".rds"))) {
  begin.time <- proc.time()
  fit <- sampling(model,                  # Stan model. 
                  data = standata,        # Data.
                  iter = 2000,            # Number of iterations.
                  chains  = 3,            # Number of chains.
                  warmup  = 500,          # Burn-in samples.
                  init    = tvdpcm_inits, # Initial values
                  seed = 2022,            # Seed
                  pars = c("beta", "theta", "lambda",
                           "sigma2", "pvar", "attractor"),
                  control = list(adapt_delta   = 0.99,
                                 max_treedepth = 15) # Other parameters to control sampling behavior.
                  ) 
  run.time <- proc.time() - begin.time
  rm(begin.time)
  
  saveRDS(fit, file = paste0(rdsfile, ".rds"))
  saveRDS(run.time, file = paste0(rdsfile, "_time.rds"))
} else {
  fit      <- readRDS(paste0(rdsfile, ".rds"))
  run.time <- readRDS(paste0(rdsfile, "_time.rds"))
}
```

```{r diag-pa}
stan.diag <- monitor(extract(fit, permuted = FALSE, inc_warmup = FALSE), 
                                 warmup = 0, print = FALSE)
            
ndiv  <- get_num_divergent(fit)     # number of divergent transitions
nbfmi <- get_low_bfmi_chains(fit)   # number of chains with a low bayesian fraction missing information 
ntree <- get_num_max_treedepth(fit) # number of transitions that exceeded the maximum treedepth
nbulk <- sum(stan.diag$Bulk_ESS < 100 * dim(fit)[2]) # number of parameters with low bulk ESS
ntail <- sum(stan.diag$Tail_ESS < 100 * dim(fit)[2]) # number of parameters with low tail ESS
          
            #max Rhat
maxRhat <- round(max(rhat(fit, pars = c("beta", "theta", "lambda", 
                                        "sigma2", "pvar", "attractor"))), 4)
nRhat   <- sum(rhat(fit, pars = c("beta", "theta", "lambda",
                                  "sigma2", "pvar", "attractor")) > 1.05)
```

```{r rhats-pa, fig.cap = "Gelman-Rubin Statistics for the Estimated Parameters of the TV-DPCM"}
mcmc_rhat(rhat(fit))
```

```{r trace-pa, fig.cap = "Traceplots of Selected Parameters"}
parameters <- c(paste0("beta[", sample(1:I, 1), ",", sample(1:(K - 1), 1), "]"),
                paste0("theta[", sample(which(!is.na(responses[, 1])), 1), "]"),
                "lambda", "sigma2")
fit.array <- as.array(fit, pars = parameters)

parameters[1] = gsub("beta", "delta", parameters[1])
parameters[1] = gsub(",", "", parameters[1])
parameters[2] = parameters[2]
parameters[3] = 'varphi'
parameters[4] = 'Psi'

dimnames(fit.array) [[3]] <- parameters

mcmc_trace(fit.array, facet_args = list(labeller = "label_parsed"))
```

```{r acf-plots-pa, fig.cap = "Autocorrelation Plots of Selected Parameters"}
mcmc_acf(fit.array, 
         facet_args = list(labeller = "label_parsed"),
         lags = 20)
```

```{r estimates-pa}
estimates <- as.data.frame(summary(fit, pars = c("beta", "lambda", "sigma2"))$summary)

estimates <- estimates[, c(1, 3, 4, 8, 9)]

estimates[, 3] <- paste0("(", round(estimates[, 3], 2), ",", round(estimates[, 4], 2), ")")

estimates        <- estimates[, -4]

names(estimates) <- c("Mean", "SD", "C.I.", "ESS")

row.names(estimates) <- c(paste0("$\\delta_{", 
                                 rep(1:I, each = K - 1), 
                                 rep(1:(K - 1), times = I),
                                 "}$"),
                          "$\\varphi$", "$\\Psi$")

# Extract all estimates
sum.fit <- list()

sum.fit$beta   <- summary(fit, pars = "beta")$summary
sum.fit$theta  <- summary(fit, pars = "theta")$summary
sum.fit$lambda <- summary(fit, pars = "lambda")$summary
sum.fit$sigma2 <- summary(fit, pars = "sigma2")$summary
sum.fit$pvar  <- summary(fit, pars = "pvar")$summary
sum.fit$attractor <- summary(fit, pars = "attractor")$summary

# Create index to plot latent dynamics
index <- trunc(seq(1, standata$nT, length.out = 200))
```

```{r est-table-pa}
kbl(estimates, align = "c", booktabs = TRUE, caption = "Estimated Parameters of the TV-DPCM", escape = FALSE, digits = c(2, 2, NA, 0))
```

```{r est-trend-pa, fig.cap = "Estimated Latent State Dispositions and Trend"}
plot(standata$time[index], sum.fit$theta[, 1][index],
     type = "l", ylim = c(-8, 8), col = gray(0.5), lwd = 1,
     ylab = "Latent State Disposition", xlab = "Beep Number")
polygon(c(standata$time, rev(standata$time)),
        c(sum.fit$attractor[, 4], rev(sum.fit$attractor[, 8])),
        border = NA,
        col = gray(0.75, 0.25))
# polygon(c(standata$time, rev(standata$time)),
#         c(sum.fit$theta[, 4], rev(sum.fit$theta[, 8])),
#         border = NA,
#         col = rgb(1, 0, 0, 0.25))
lines(standata$time, sum.fit$attractor[, 1],
      col = 1, lwd = 2)
```

```{r ICC-pa, fig.height = 6, fig.cap = "Item Characteristic Functions for the Mental Unrest Items"}
par(mfrow = c(5, 1))

plot.ICC(object = fit, data = standata, range = c(-8, 8), quiet = TRUE,
         item_labels = c("Relaxed", "Satisfied", "Enthusiastic",
                         "Cheerful", "Strong"), 
         col = gray((0:(K - 1))/K))
```

```{r IIF-pa, fig.cap = "Item Information Functions of the Items of Mental Unrest"}
plot.IIF(object = fit, data = standata, type = "IIF", 
         item_labels = c("Relaxed", "Satisfied", "Enthusiastic",
                         "Cheerful", "Strong"), 
         col = gray((0:(I-1))/I), range = c(-8, 8))

```

```{r TIF-pa, fig.cap = "Test Information Function of the Items of Mental Unrest"}
plot.IIF(object = fit, data = standata, range = c(-8, 8), type = "TIF")
```

```{r clean4}
rm(estimates, fit, responses, stan.diag, standata,
   sum.fit, fit.array, I, index, K, maxRhat,
   nbfmi, nbulk, ndiv, nRhat, nT, ntail, ntree,
   parameters, rdsfile, run.time)
```

\newpage

```{r select-variables}
PG_PCA <- PG_data[, c(grep("mood", names(PG_data))[-13], grep("pat", names(PG_data)))]
```

```{r PCA}
PCA_fit <- prcomp(na.omit(PG_PCA[, -c(1, 2, 8, 15, 16)]), center = TRUE, scale = TRUE)
PCA_fit2 <- psych::principal(PG_PCA[, -c(1, 2, 8, 15, 16)], nfactors = 3)
```

```{r PCA2}
PCA_fit <- prcomp(na.omit(PG_PCA), center = TRUE, scale = TRUE)
PCA_fit2 <- psych::principal(PG_PCA, nfactors = 3)
```

\newpage

# References



