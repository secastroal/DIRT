---
title: "Testing Posterior Predictive Model Checking for the Time-Varying Dynamic Partial Credit Model"
author: "Sebastian Castro-Alvarez"
date: "`r format(Sys.Date(), '%B %d del %Y')`"
header-includes:
  - \usepackage{booktabs}
  - \usepackage{longtable}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage{float}
  - \usepackage{amsmath}
output: 
  pdf_document:
    toc: false
bibliography: references.bib
csl: apa7.csl
link-citations: true
always_allow_html: true
---

```{r setup, include=FALSE}
library(knitr)
library(kableExtra)
knitr::opts_chunk$set(echo = FALSE, fig.height = 5, fig.width = 8,  
                      warning=FALSE, message=FALSE)

library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
library(bayesplot)
library("splines")

source("../R/IRT_models.R")
source("../R/IRT_plots.R")
source("../R/PPMC.R")
source("../R/genTVDPCM.R")
source("../R/tvdpcm2stan.R")
```

```{r seed}
seed <- 1005
set.seed(seed)
```

```{r setmodel}
# Use TVPCM, ARPCM, or PCM
setmodel <- "TVPCM"
# render("Rmarkdown/PPMC_Tests.Rmd", output_file = paste0("Rmarkdown/PPMC_Tests_", setmodel, "_", seed))
```

In this document, we test the posterior predictive model checking methods that we are developing for the time-varying dynamic partial credit model (TV-DPCM). For this, we simulated data based on the TV-DPCM as well as data that violates some of the assumptions of the model.

# TV-DPCM

The time-varying dynamic partial credit model is a model that aims to analyze the psychological time series of one individual. Consider for example that a person that is attending therapy is requested to report their emotions multiple times on a daily basis to monitor their progress. Thus, the person has to answer multiple likert-scale questions (the same questions every time) about how they feel. Moreover, we assume that some of these emotions measure a construct such as positive or negative affect. Given this situation, the observed data are categorical time series from a single individual. To analyze such data, we developed the time-varying dynamic partial credit model. 

This model combines two frameworks: The item response theory [@Embretson2000] and the time-varying vector autoregressive model [@Bringmann2017]. In particular, the measurement component of the model uses the partial credit model [@Masters2016] to relate the responses to the items with the latent construct of interest. Then, at the latent level, the latent variable, which represents the latent state dispositions of the individual at each time point, is modeled by means of a time-varying autoregressive model [@Bringmann2017]. In this case, we only allow the intercept of the autoregressive model to vary over time while the autoregressive effect is assumed to be time invariant. Thus, the intercept is further modeled with the generalized additive model with splines [@Wood2017]. This allows the time series to follow a non linear (smooth) trend. To be more precise, the model is defined in two equations: The measurement equation and the structural equation. The measurement equation defines the measurement model that relates the responses with the latent construct, namely, the PCM, which is as follows:

$$
P(X_i = x|\theta_t) = \frac{exp\Big[\sum\limits_{k=0}^{x}(\theta_t - \delta_{ik})\Big]}{\sum\limits_{v=0}^{m_{i}}exp\Big[\sum\limits_{k=0}^{v}(\theta_t - \delta_{ik})\Big]},
$$

where $\theta_{t}$ is the latent state disposition at time $t$ and $\delta_{ik}$ is the step parameter of the $k$-th category of the $i$-th item. Then, the latent state dispositions ($\theta_t$) are further modeled at the structural equation with the TV-AR model. This means that $\theta_t$ is regressed on a lagged version of itself, resulting in the following equation:

$$
\theta_{t} = \alpha_{t} + \varphi\theta_{t-1} + \varepsilon_{t},
$$

where $\alpha_t$ is the time varying intercept of the dynamic process, $\varphi$ is the time invariant autoregressive effect between consecutive latent state dispositions, and $\varepsilon_{t}$ is the residual, also known as the innovation, at time $t$. Lastly, the time varying intercepts ($\alpha_t$) are further modeled as a function of time with a generalized additive model. This means that:

$$
\alpha_{t} = f(t) = \sum\limits_{j=1}^{s}b_{j}(t)\beta_{j},
$$

where $b_j(t)$ is a function of time, which is known as a basis function. These basis functions can be specified in many different ways given a certain smoother [@Wood2017]. In this particular implementation, we define the basis functions based on B-splines.

\newpage

# Data Simulation

In this example, we simulated six data sets. The first data set perfectly matches the proposed TV-DPCM. The second data set is a constrained version of the TV-DPCM model in which the intercept does not vary over time. A third data set assumes that the latent structure is bidimensional instead of unidimensional. The fourth data set assumes that there is item parameter drift (i.e., the item parameters change over time). The fifth data set simulates data based on the generalized PCM, in other words, it allows the discrimination parameters to vary across items. Lastly, the last data set simulates a TV-DPCM of order 3 (i.e., the latent state disposition is regressed on the three previous time points). For these data sets, we simulated 200 time points of 6 items each with 5 response options. Moreover, the autoregressive effect is set at 0.5 and the variance of the innovations is set to 1.  

```{r fixvalues}
nT     <- 200   # Number of time points
I      <- 6     # Number of items
K      <- 5     # Number of categories per item
M      <- K - 1 # Number of thresholds per item
lambda <- 0.5   # Size of the autoregressive effect
in_var <- 1     # Variance of the innovations
```

Data1 perfectly matches the TV-DPCM. In this case, we simulate the time-varying intercept based on sinusoidal trend with one and a half period. The simulated time series of the sumscores are presented in following figure: 

```{r data1}
# Generate Data based on the TV-DPCM
dataTRUE <- gen.TVDPCM(nT = nT, 
                       I  = I, 
                       K  = K, 
                       pop.param = list(lambda = lambda), 
                       seed = seed, 
                       FUN  = "sinusoidal",
                       maxAbsValue = 1)

data1 <- dataTRUE$data
```

```{r data1_plot}
plot(rowSums(data1), type = "l", ylab = "sumscores", xlab = "Time",
     las = 1, lwd = 2)
```

Secondly, Data2 was simulated based on a simpler version of the model that does not allow the intercept to vary over time. In this case, the latent variable is also modeled after an autoregressive model, but the structure is assumed to be stationary. Therefore, there are not trends in the time series. In this case, the simulated time series of the sumscores look like this:

```{r data2}
# Simulate data with no trend
data2 <- gen.TVDPCM(nT = nT,
                    I  = I,
                    K  = K,
                    pop.param = list(lambda = dataTRUE$lambda.gen,
                                     sigma2 = dataTRUE$sigma2.gen,
                                     thresholds = dataTRUE$thresholds.gen),
                    seed = seed,
                    FUN = function(x) {rep(0, nT)})

data2 <- data2$data
```

```{r data2_plot}
plot(rowSums(data2), type = "l", ylab = "sumscores", xlab = "Time",
     las = 1, lwd = 2)
```

The next data set (Data3) assumes that the factor structure is bidimensional instead of unidimensional. The two factors are correlated ($r = 0.5$). The latent process of these two factors was also simulated based on an autoregressive model without time varying parameters. Thus, the simulated time series of the sumscores of each factor and the whole scale are presented in the following figure:

```{r data3}
# Now, theta is a matrix with two factors that are weakly correlated.
theta <- matrix(NA, nrow = nT, ncol = 2)
mu    <- c(0, 0)
Sigma <- matrix(c(1, 0.5, 0.5, 1), 2)

theta[1, ] <- MASS::mvrnorm(1, mu = mu, Sigma = Sigma)

for (i in 2:nT) {
  theta[i, ] <- lambda * theta[i - 1, ] + MASS::mvrnorm(1, mu = mu, Sigma = Sigma) 
}
rm(i, mu, Sigma)

# Now, let's use the same item parameters to generate the data but using three
# items for one factor and three items for the other factor.
# Location
delta <- rowMeans(dataTRUE$thresholds.gen)
  
# Steps
taus  <- dataTRUE$thresholds.gen - delta

# Responses factor 1
probs.array <- array(NA, dim = c(dim(theta)[1], I / 2, K))

for (y in 0:M) {
  probs.array[, , y + 1] <- P.GPCM(y     = y, 
                                   alpha = rep(1, I / 2), 
                                   delta = delta[1:3], 
                                   taus  = taus[1:3, ], 
                                   theta = theta[, 1], 
                                   M     = M)
}
responses1   <- apply(probs.array, 1:2, function(vec) {which( rmultinom(1, 1, vec) == 1) - 1 })
responses1   <- responses1 + 1 # To fit the PCM in stan, items should be coded starting from 1. 
rm(probs.array, y)

# Responses factor 2
probs.array <- array(NA, dim = c(dim(theta)[1], I / 2, K))

for (y in 0:M) {
  probs.array[, , y + 1] <- P.GPCM(y     = y, 
                                   alpha = rep(1, I / 2), 
                                   delta = delta[4:6], 
                                   taus  = taus[4:6, ], 
                                   theta = theta[, 2], 
                                   M     = M)
}
responses2   <- apply(probs.array, 1:2, function(vec) {which( rmultinom(1, 1, vec) == 1) - 1 })
responses2   <- responses2 + 1 # To fit the PCM in stan, items should be coded starting from 1. 
rm(probs.array, y)

responses <- cbind(responses1, responses2)
rm(responses1, responses2)

data3 <- responses
```

```{r data3_plot}
plot(rowSums(data3), type = "l", ylab = "sumscores", xlab = "Time",
     las = 1, ylim = c(2.75, 30.25), lwd = 2)
lines(rowSums(data3[, 1:3]), col = "blue", lwd = 2)
lines(rowSums(data3[, 4:6]), col = "darkgreen", lwd = 2)
legend("topright", c("Total", "Factor 1", "Factor 2"),
       col = c("black", "blue", "darkgreen"), lty = 1, lwd = 2)

```

Next, Data4 assumes that the item parameters change over time. For this, we keep the same generated thetas as the ones use to generate Data1. We also use the same item parameters as we used for the other data sets to generate the first half of the responses. In contrast, for the second half of the responses, the thresholds parameters are modified by resting 1.5 to all of them. This means that the individual is more likely to endorse high responses on the second half of the measurement. Now, the following figure presents the simulated time series:

```{r data4}
# Use same theta as in data1
theta <- dataTRUE$theta.gen

# Create item parameters for the second half.
thresholds2 <- dataTRUE$thresholds.gen - 1.5

# Location
delta2 <- rowMeans(thresholds2)

# Step parameters
taus2 <- thresholds2 - delta2

# Generate responses  half 1
probs.array <- array(NA, dim = c(length(theta)/2, I, K))

for (y in 0:M) {
  probs.array[, , y + 1] <- P.GPCM(y     = y, 
                                   alpha = rep(1, I), 
                                   delta = delta, 
                                   taus  = taus, 
                                   theta = theta[1:100], 
                                   M     = M)
}
responses1   <- apply(probs.array, 1:2, function(vec) {which( rmultinom(1, 1, vec) == 1) - 1 })
responses1   <- responses1 + 1 # To fit the PCM in stan, items should be coded starting from 1. 
rm(probs.array, y)

# Generate responses  half 2
probs.array <- array(NA, dim = c(length(theta)/2, I, K))

for (y in 0:M) {
  probs.array[, , y + 1] <- P.GPCM(y     = y, 
                                   alpha = rep(1, I), 
                                   delta = delta2, 
                                   taus  = taus2, 
                                   theta = theta[101:200], 
                                   M     = M)
}
responses2   <- apply(probs.array, 1:2, function(vec) {which( rmultinom(1, 1, vec) == 1) - 1 })
responses2   <- responses2 + 1 # To fit the PCM in stan, items should be coded starting from 1. 
rm(probs.array, y)

responses <- rbind(responses1, responses2)
rm(responses1, responses2)

data4 <- responses
```

```{r data4_plot}
plot(rowSums(data4[1:100, ]), type = "l", ylab = "sumscores", xlab = "Time",
     las = 1, xlim = c(1, 200), lwd = 2, col = "blue")
lines(100:200, rowSums(data4[100:200, ]), col = "darkgreen", lwd = 2)
```

The fifth dataset (Data5) simulates data using the GPCM instead of the PCM for the measurement equation. This means that the discrimination parameters vary across items. The discrimination parameters are generated based on a lognormal distribution with mean 0 and standard deviation 0.25. The simulated data is presented in following Figure:

```{r data5}
# Generate Data based on the TV-DPCM using the GPCM for the measurement model.
data5 <- gen.TVDPCM(nT = nT, 
                    I  = I, 
                    K  = K, 
                    pop.param = list(lambda = dataTRUE$lambda.gen,
                                     sigma2 = dataTRUE$sigma2.gen,
                                     thresholds = dataTRUE$thresholds.gen,
                                     theta = dataTRUE$theta.gen,
                                     alpha = rlnorm(I, 0, 0.25)), 
                    seed = seed, 
                    FUN  = "sinusoidal",
                    maxAbsValue = 1)

data5 <- data5$data
```

```{r data5_plot}
plot(rowSums(data5), type = "l", ylab = "sumscores", xlab = "Time",
     las = 1, lwd = 2)
```

Finally, the last data set (Data6) is simulated based on a dynamic process of order 3. This means that the latent state disposition at time $t$ has an effect on the latent state disposition at time $t + 3$. The observed time series of Data6 are presented in the following Figure:

```{r data6}
# Generate the dynamic process of order 3.
# Define autoregressive effect up to lag 3.
lambda <- c(0.3, 0.2, 0.1)

# Use the same time varying intercept as in Data1.
tv_int <- sinusoidal(nT, 1)
tv_int <- c(tv_int * -1, tv_int)

# We generate a dynamic process twice the required length and the drop the first 
# half
theta <- rep(NA, nT * 2)

# The three first thetas are randomly generated.
theta[1:3] <- rnorm(1, 0, sqrt(dataTRUE$sigma2.gen))

for (t in 4:(nT * 2)) {
      theta[t] <- tv_int[t] + lambda[1] * theta[t - 1] +
        lambda[2] * theta[t - 2] + lambda[3] * theta[t - 3] +
        rnorm(1, 0, sqrt(dataTRUE$sigma2.gen))
    }
    rm(t)

theta <- theta[(nT + 1):(nT * 2)]

# Generate Data based on the TV-DPCM
data6 <- gen.TVDPCM(nT = nT, 
                    I  = I, 
                    K  = K, 
                    pop.param = list(lambda = lambda[1],
                                     sigma2 = dataTRUE$sigma2.gen,
                                     thresholds = dataTRUE$thresholds.gen,
                                     theta = theta), 
                    seed = seed, 
                    FUN  = "sinusoidal",
                    maxAbsValue = 1)

data6 <- data6$data
```

```{r data6_plot}
plot(rowSums(data6), type = "l", ylab = "sumscores", xlab = "Time",
     las = 1, lwd = 2)
```

In the next section, we proceed to analyze the simulated data sets with the TV-DPCM and to compute several posterior predictive model checking methods.

\newpage

# Posterior Predictive Model Checking Methods

In this section, we fit the TV-DPCM to all the generated data sets. To run the algorithm, we used 3 parallel chains and 2000 iterations per chain, of which 500 were discarded as burn-in. For the B-splines, we used 8 internal knots, which means that we used 10 basis functions to model the trend. Once the estimation of the model was finished, we computed some of the posterior predictive model checking methods and modified versions of these methods that have been proposed for IRT in @Li2017, @Sinharay2006a, and @Zhu2011. First, to verify that the models converged, we looked at the warning messages from Stan. These messages indicate if there were divergent transitions, if there were Gelman-Rubin statistics larger than 1.05, and other checks available in Stan. These diagnostic checks are presented in the following Table for each data set. If the estimation of the model finished without any issues, all the different warnings must be 0. 

```{r selectmodel}
if (setmodel == "TVPCM") {
  modelfile   <- "tv_dpcm_int_v5.1.stan"
  paramsample <- c("beta", "theta", "lambda", "sigma2", "pvar", 
                   "attractor", "rep_y")
  paramplot   <- c("beta[3,3]", "theta[100]", "attractor[50]", 
                   "lambda", "sigma2", "pvar")
  inits <- function() {
  list(lambda = runif(1, -1, 1),
       beta   = array(rnorm(I * (K - 1), 0, 3), dim = c(I, K - 1)),
       inno   = rnorm(nT, 0, 3),
       sigma  = rlnorm(1, 1))
  }
}

if (setmodel == "ARPCM") {
  modelfile   <- "ar_irt_pcm_na_free.stan"
  paramsample <- c("beta", "theta", "lambda", "sigma2", "rep_y")
  paramplot   <- c("beta[1,1]", "beta[3,3]", "beta[6,4]", "theta[1]", 
                   "theta[100]", "theta[200]", "lambda", "sigma2")
  inits <- function() {
  list(lambda = runif(1, -1, 1),
       beta   = array(rnorm(I * (K - 1), 0, 3), dim = c(I, K - 1)),
       inno   = rnorm(nT, 0, 3),
       sigma2 = rlnorm(1, 1))
  }
}

if (setmodel == "PCM") {
  modelfile   <- "irt_pcm_long.stan"
  paramsample <- c("beta", "theta", "rep_y")
  paramplot   <- c("beta[1,1]", "beta[3,3]", "beta[6,4]", "theta[1]", 
                   "theta[100]", "theta[200]")
  inits <- function() {
  list(beta   = array(rnorm(I * (K - 1), 0, 3), dim = c(I, K - 1)),
       theta   = rnorm(nT, 0, 3))
  }
}

```


```{r stanfit}
model <- stan_model(file = paste0("../Stan/", modelfile), verbose = FALSE)

datasets <- list(data1, data2, data3, data4, data5, data6)
standata <- list()
fit      <- list()

# Fit the TV-DPCM model with stan
for (i in 1:6) {

responses <- datasets[[i]]

standata[[i]] <- tvdpcm2stan_data(resp = responses,
                                  I = I,
                                  K = K,
                                  nT = nT,
                                  n_knots = 8,
                                  s_degree = 3)
            
begin.time <- proc.time()
fit[[i]] <- sampling(model,                            # Stan model. 
                     data = standata[[i]],             # Data.
                     iter = 2000,                      # Number of iterations.
                     chains  = 3,                      # Number of chains.
                     warmup  = 500,                   # Burn-in samples.
                     init    = inits,
                     seed    = seed,
                     pars    = paramsample,
                     control = list(adapt_delta=0.99, max_treedepth = 15)) # Other parameters to control sampling behavior.
run.time <- proc.time() - begin.time
rm(begin.time)
            
}
```

```{r diagnostics, results='hide'}

diag <- lapply(fit, function (x) {
  monitor(extract(x, permuted = FALSE, inc_warmup = FALSE), warmup = 0)
})

diag.table <- matrix(NA, nrow = 6, ncol = 6)
colnames(diag.table)  <- paste0("Data", 1:6)
row.names(diag.table) <- c("Rhat>1.05", "N. Divergent", "N. Low BFMI", 
                           "Excedeed Treedepth", "Low Bulk ESS", "Low Tail ESS")

diag.table[1, ] <- unlist(
  lapply(fit, function(x) {
    sum(rhat(x, pars = head(paramsample, -1)) > 1.05)
    }))

diag.table[2, ] <- unlist(
  lapply(fit, get_num_divergent)
)

diag.table[3, ] <- unlist(
  lapply(fit, function(x) length(get_low_bfmi_chains(x)))
)

diag.table[4, ] <- unlist(
  lapply(fit, get_num_max_treedepth)
)

diag.table[5, ] <- unlist(
  lapply(diag, function(x) sum(x$Bulk_ESS < 300))
)

diag.table[6, ] <- unlist(
  lapply(diag, function(x) sum(x$Tail_ESS < 300))
)
```

```{r diag_table}
kbl(diag.table, align = "c", booktabs = TRUE)
```

```{r pairs_plot, eval = FALSE}
for (i in 1:4) {
  pairs(fit[[i]], pars = paramplot, log = TRUE, las = 1)
}
rm(i)
```

```{r rhat_plot, fig.height = 8, eval = FALSE}
par(mfrow = c(2, 2))
for (i in 1:4) {
  print(mcmc_rhat(rhat(fit[[i]])))
}
rm(i)
```

```{r trace_plot, eval = FALSE}
for (i in 1:4) {
  print(traceplot(fit[[i]], pars = paramplot, 
                  inc_warmup = FALSE))
}
rm(i)
```

In what follows, different posterior predictive model checking methods are applied on the fitted models in order to illustrate how they work and to explore whether they are useful to identify model misfit. We expect some of this methods to show misfit on Data3 to Data6, as these simulated data sets clearly violate some of the assumptions of the TV-DPCM. In contrast, the fitted models to Data1 and Data2 should not show model misfit given that Data1 perfectly matches the model and Data2 was simulated based on a simplified version of the model.

\newpage

## Sumscores Time Series

A popular test level measure to assess model fit of IRT models is the Test Score distribution [@Li2017, @Zhu2011], which compares the test score distribution of the observed data with the replicated data. However, assessing the test score distribution did not seem to be adequate for the TV-DPCM model as it does not take into account the time component. Because of this, we compared the observed and the replicated time series of the test scores instead. In the next Figure, we plotted the observed test scores against the median test score of the replicated data with its 95\% percentile band of the replicated scores. If a large amount of observed scores are out of the 95\% percentile band, it would indicate some sort of model misfit.   

```{r sums_ts, fig.height = 8}
par(mfrow = c(6, 1), oma = c(1, 3, 1, 1))
for(i in 1:6) {
  ppmc.sumscore.ts(fit[[i]], standata[[i]])
}
rm(i)
```

\newpage

## Autocorrelation: 1st, 2nd, and 3rd

```{r acf, fig.height = 8}
par(mfrow = c(4, 3))
for(i in 1:4) {
  ppmc.acf(fit[[i]], standata[[i]], lag.max = 3)
}
rm(i)
```

## Autocorrelation of the Residuals: 1st

```{r racf, fig.height = 8}
par(mfrow = c(2, 2))
for(i in 1:4) {
  ppmc.racf(fit[[i]], standata[[i]])
}
rm(i)
```

## Mean Squared Succesive Differences

```{r racf, fig.height = 8}
par(mfrow = c(2, 2))
for(i in 1:4) {
  ppmc.mssd(fit[[i]], standata[[i]])
}
rm(i)
```


## Items Scores Time Series: Item 1

```{r item_ts, fig.height = 8}
par(mfrow = c(4, 1))
for(i in 1:4) {
  ppmc.item.ts(fit[[i]], standata[[i]], quiet = TRUE, items = 1)
}
rm(i)
```

## Item-Total Correlation: Version 1
Data1:
```{r itcor_1, fig.height = 6, results='hide'}
par(mfrow = c(2, 3))
ppmc.itcor(fit[[1]], standata[[1]], quiet = TRUE, method = "pearson")
```
Data2:
```{r itcor_2, fig.height = 6, results='hide'}
par(mfrow = c(2, 3))
ppmc.itcor(fit[[2]], standata[[2]], quiet = TRUE, method = "pearson")
```
Data3:
```{r itcor_3, fig.height = 6, results='hide'}
par(mfrow = c(2, 3))
ppmc.itcor(fit[[3]], standata[[3]], quiet = TRUE, method = "pearson")
```
Data4:
```{r itcor_4, fig.height = 6, results='hide'}
par(mfrow = c(2, 3))
ppmc.itcor(fit[[4]], standata[[4]], quiet = TRUE, method = "pearson")
```

## Item-Total Correlation: Version 2
Data1:
```{r itcor2_1, fig.height = 6, results='hide'}
par(mfrow = c(2, 3))
ppmc.itcor2(fit[[1]], standata[[1]], quiet = TRUE, method = "polyserial")
```
Data2:
```{r itcor2_2, fig.height = 6, results='hide'}
par(mfrow = c(2, 3))
ppmc.itcor2(fit[[2]], standata[[2]], quiet = TRUE, method = "polyserial")
```
Data3:
```{r itcor2_3, fig.height = 6, results='hide'}
par(mfrow = c(2, 3))
ppmc.itcor2(fit[[3]], standata[[3]], quiet = TRUE, method = "polyserial")
```
Data4:
```{r itcor2_4, fig.height = 6, results='hide'}
par(mfrow = c(2, 3))
ppmc.itcor2(fit[[4]], standata[[4]], quiet = TRUE, method = "polyserial")
```


## Item-Total Correlation: Version 3
Data1:
```{r itcor3_1, fig.height = 6, results='hide'}
par(mfrow = c(2, 3))
ppmc.itcor3(fit[[1]], standata[[1]], quiet = TRUE)
```
Data2:
```{r itcor3_2, fig.height = 6, results='hide'}
par(mfrow = c(2, 3))
ppmc.itcor3(fit[[2]], standata[[2]], quiet = TRUE)
```
Data3:
```{r itcor3_3, fig.height = 6, results='hide'}
par(mfrow = c(2, 3))
ppmc.itcor3(fit[[3]], standata[[3]], quiet = TRUE)
```
Data4:
```{r itcor3_4, fig.height = 6, results='hide'}
par(mfrow = c(2, 3))
ppmc.itcor3(fit[[4]], standata[[4]], quiet = TRUE)
```

## Yen's Q1

Data1:
```{r q1_1, fig.height = 6, results='hide'}
par(mfrow = c(2, 3))
ppmc.Q1(fit[[1]], standata[[1]], quiet = TRUE)
```

Data2:
```{r q1_2, fig.height = 6, results='hide'}
par(mfrow = c(2, 3))
ppmc.Q1(fit[[2]], standata[[2]], quiet = TRUE)
```

Data3:
```{r q1_3, fig.height = 6, results='hide'}
par(mfrow = c(2, 3))
ppmc.Q1(fit[[3]], standata[[3]], quiet = TRUE)
```

Data4:
```{r q1_4, fig.height = 6, results='hide'}
par(mfrow = c(2, 3))
ppmc.Q1(fit[[4]], standata[[4]], quiet = TRUE)
```

## Yen's Q1 modified

Data1:
```{r q1alt_1, fig.height = 6, results='hide'}
par(mfrow = c(2, 3))
ppmc.Q1.alt(fit[[1]], standata[[1]], quiet = TRUE)
```

Data1:
```{r q1alt_2, fig.height = 6, results='hide'}
par(mfrow = c(2, 3))
ppmc.Q1.alt(fit[[2]], standata[[2]], quiet = TRUE)
```

Data1:
```{r q1alt_3, fig.height = 6, results='hide'}
par(mfrow = c(2, 3))
ppmc.Q1.alt(fit[[3]], standata[[3]], quiet = TRUE)
```

Data4:
```{r q1alt_4, fig.height = 6, results='hide'}
par(mfrow = c(2, 3))
ppmc.Q1.alt(fit[[4]], standata[[4]], quiet = TRUE)
```

# Yen's Q3

```{r q3_1, fig.height = 6, results='hide'}
for (i in 1:4) {
  ppmc.Q3(fit[[i]], standata[[i]])
}
```


# OR 

```{r OR_1, fig.height = 6, results='hide'}
for (i in 1:4) {
  ppmc.OR(fit[[i]], standata[[i]])
}
```

# OR Modified

```{r ORdiff_1, fig.height = 6, results='hide'}
for (i in 1:4) {
  ppmc.ORDiff(fit[[i]], standata[[i]])
}
```

# RESID

```{r resid_1, fig.height = 6, results='hide'}
for (i in 1:4) {
  ppmc.cov.resid(fit[[i]], standata[[i]])
}
```

# RESID Diff

```{r resid_1, fig.height = 6, results='hide'}
for (i in 1:4) {
  ppmc.cov.rediff(fit[[i]], standata[[i]])
}
```


# References
